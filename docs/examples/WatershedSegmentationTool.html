
<!DOCTYPE html>
<html class="h-100 overflow-hidden">
  <head>
    <meta http-equiv="Content-type" content="text/html" charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, height=device-height, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
    <link
      rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/vs2015.min.css"
    />
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
    <script>
      hljs.highlightAll();
    </script>
<title>Watershed segmentation implemented in OpenCV.js</title>
</head>

<body class="h-100" style="background-color: #000000">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script>
    <div class="row h-100" >
        <div
          id="viewer"
          class="col-8 h-100"
          style="background-color: black"
        > 
        <div id="demo-title-container">
          <h1 id="demo-title" style="color:#ffffff; font-family:sans-serif; margin-left:22%;">
            Watershed segmentation implemented in OpenCV.js
          </h1>
        </div>
        <div id="demo-description-container">
          <p id="demo-description" style="color:#8400a9; font-family:sans-serif; margin-left:18%;">
            Displays a single DICOM image with watershed segmentation applied
          </p>
        </div>
        <p id="status">OpenCV.js status: Loading...</p>

    <div class="row">
            <div class="column" style="
                flex: 33.33%;
                padding: 5px;
              ">
        <img id="imageSrc" alt="No Image" />
        <div class="caption">image upload</div>
    </div>
    <div class="column" style="
    flex: 33.33%;
    padding: 5px;
  ">
    <canvas id="canvasOutput"></canvas>
    <div class="caption">Segmented image</div>
</div>
</div>
</div>
      <div class="col-4 h-100" >
      <pre class="h-100">
        <code class="typescript" style="background-color: #000000">
          <p style="font-size:0.7vw;">
/*Hahn and Peitgen [2000] extracted the brain with a single watershed transform from MRI data. 
Also, the cerebral ventricles were reliably segmented with minimal interaction. 
Hahn and Peitgen [2003] demonstrated the application to the challenging problem of
delineating individual bones in the human wrist (see Fig. 4.17). 
Kuhnigk et al. [2003] employed the above-described variant of the watershed segmentation 
to the delineation of lung lobes in CT data. 
Ray et al. [2008] used the iterative watershed transform 
for hepatic tumor segmentation (and volumetry).*/

let fileName = "anon1" ;

async function createFile(fileName)
{
    let response=await fetch("./demo/" + fileName);
    console.log(response);
    let data=await response.blob();
    let file = new File([data], fileName);
    Render(file);
} 


   async function Render(file) {

        cornerstoneWADOImageLoader.external.cornerstone = cornerstone;
        cornerstoneWADOImageLoader.external.dicomParser = dicomParser;
        cornerstoneWADOImageLoader.configure({
        useWebWorkers: true,
        decodeConfig: {
            convertFloatPixelDataToInt: false,
        },
    });

var config = {
maxWebWorkers: navigator.hardwareConcurrency || 1,
startWebWorkersOnDemand: false,
taskConfiguration: {
decodeTask: {
  initializeCodecsOnStartup: true,
  strict: false,
},
},
};

cornerstoneWADOImageLoader.webWorkerManager.initialize(config);
    larvitar.resetLarvitarManager();

    let pixel_array=[];

        debugger;
        let imageId = cornerstoneWADOImageLoader.wadouri.fileManager.add(file);
        console.log(imageId);

       await cornerstone.loadImage(imageId).then((image) => {
        pixel_array=image.getPixelData(); console.log(image);
        console.log(pixel_array);
    
        let max_pixel_value= pixel_array.reduce((a, b) => Math.max(a, b), -Infinity);
        let scaled_array=[];

    for (i=0; i less than pixel_array.length;i++)
    {
    let scaled_array_item=(Math.max(pixel_array[i],0)/max_pixel_value)*255;
    scaled_array.push(scaled_array_item);
     }
    console.log(scaled_array);
    let scaled_array_8bit = new Uint8Array(scaled_array);
    console.log(scaled_array_8bit);
    // Once the image is loaded, you can display it, convert it, or perform other operations.
  // To convert it to PNG, you can use a canvas.
  const canvas = document.createElement('canvas');
  const context = canvas.getContext('2d');
  canvas.width = image.width;
  canvas.height = image.height;

  cornerstone.renderToCanvas(canvas, image);
  
  // Convert the canvas to a PNG data URL
  const pngDataUrl = canvas.toDataURL('image/png');
  const url= pngDataUrl;
  let imgElement = document.getElementById("imageSrc");
    imgElement.src=url;
    imgElement.onload=function(){
        console.log(this.width + 'x' + this.height);
        Segment(imgElement);};
    })}

  function Segment(imgElement){


        console.log(cv);
        console.log("you are here");
        console.log(imgElement);
        let src = cv.imread(imgElement);
        console.log(src);
        //cv.imshow('canvasInput', src);
        let dst = new cv.Mat();
        let gray = new cv.Mat();
        let opening = new cv.Mat();
        let Bg = new cv.Mat();
        let Fg = new cv.Mat();
        let distTrans = new cv.Mat();
        let unknown = new cv.Mat();
        let markers = new cv.Mat();
        // gray and threshold image
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
        cv.threshold(gray, gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU);
        // get background
        let M = cv.Mat.ones(3, 3, cv.CV_8U);
        cv.erode(gray, gray, M);
        cv.dilate(gray, opening, M);
        cv.dilate(opening, Bg, M, new cv.Point(-1, -1), 1);
        // distance transform
        cv.distanceTransform(opening, distTrans, cv.DIST_L2, 5);
        cv.normalize(distTrans, distTrans, 1, 0, cv.NORM_INF);
        // get foreground
        cv.threshold(distTrans, Fg, 0 * 1, 255, cv.THRESH_BINARY);
        Fg.convertTo(Fg, cv.CV_8U, 1, 0);
        cv.subtract(Bg, Fg, unknown);
        // get connected components markers
        cv.connectedComponents(Fg, markers);
        for (let i = 0; i less than markers.rows; i++) {
            for (let j = 0; j less than markers.cols; j++) {
             markers.intPtr(i, j)[0] = markers.ucharPtr(i, j)[0] + 1;
                if (unknown.ucharPtr(i, j)[0] == 255) {
                    markers.intPtr(i, j)[0] = 0;
                }
                }
        }
        cv.cvtColor(src, src, cv.COLOR_RGBA2RGB, 0);
        cv.watershed(src, markers);
        // draw barriers
        for (let i = 0; i less than markers.rows; i++) {
            for (let j = 0; j less than markers.cols; j++) {
                if (markers.intPtr(i, j)[0] == -1) {
                        src.ucharPtr(i, j)[0] = 255; // R
                        src.ucharPtr(i, j)[1] = 0; // G
                        src.ucharPtr(i, j)[2] = 0; // B
                    }
                }
            }
        cv.imshow('canvasOutput', src);
        src.delete(); dst.delete(); gray.delete(); opening.delete(); Bg.delete();
        Fg.delete(); distTrans.delete(); unknown.delete(); markers.delete(); M.delete();
        //pixel_array = imageObject.metadata.x7fe00010;

     };


createFile(fileName);

        </p>    
    </code>
  </pre>
</div>
<script src="../../dist/larvitar.js"></script>
<script src="../../node_modules/cornerstone-core/dist/cornerstone.js"></script>
<script src="../../node_modules/cornerstone-wado-image-loader/dist/cornerstoneWADOImageLoader.bundle.min.js"></script>
<script src="../../node_modules/dicom-parser/dist/dicomParser.js"></script>
<script src="../../node_modules/jpeg-js/lib/decoder.js"></script>
<script src="../../node_modules/jpeg-js/lib/encoder.js"></script>
<script src="https://cdn.jsdelivr.net/npm/lodash@4.17.21/lodash.min.js"></script>

<script>
function onOpenCvReady() {
    console.log( 'OpenCV Ready', cv);
    document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
  }
  </script>
<script src="https://docs.opencv.org/4.5.4/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
<script src="./WatershedSegmentationTool.js"></script>
<script>
let demoFiles = [];
      let counter = 0;

      const getDemoFileNames = function () {
        let demoFileList = [];
        for (let i = 1; i < 25; i++) {
          let filename = "anon" + i;
          demoFileList.push(filename);
        }
        return demoFileList;
      };

      // init all
      larvitar.initializeImageLoader();
      larvitar.initializeCSTools();
      larvitar.store.initialize();
      larvitar.store.addViewport("viewer");
      larvitar.registerExternalTool("Test", WatershedSegmentationTool);

      async function createFile(fileName, cb) {
        let response = await fetch("./demo/" + fileName);
        let data = await response.blob();
        let file = new File([data], fileName);
        demoFiles.push(file);
        counter++;
        if (counter == 24) {
          cb();
        }
      }

      function renderSerie() {
        larvitar.resetLarvitarManager();
        larvitar
          .readFiles(demoFiles)
          .then(seriesStack => {
            // render the first series of the study
            let seriesId = _.keys(seriesStack)[0];
            let serie = seriesStack[seriesId];
            larvitar.renderImage(serie, "viewer").then(() => {
              console.log("Image has been rendered");
            });
            // optionally cache the series
            larvitar.populateLarvitarManager(seriesId, serie);
            larvitar.cacheImages(serie, function (resp) {
              if (resp.loading == 100) {
                let cache = larvitar.cornerstone.imageCache;
                console.log(
                  "Cache size: ",
                  cache.getCacheInfo().cacheSizeInBytes / 1e6,
                  "Mb"
                );
              }
            });
            larvitar.addTool("Test");
            larvitar.setToolActive("Test");
          })
          .catch(err => console.error(err));
      }

      let demoFileList = getDemoFileNames();
      _.each(demoFileList, function (demoFile) {
        createFile(demoFile, renderSerie);
      });

/*Hahn and Peitgen [2000] extracted the brain with a single watershed transform from MRI data. 
Also, the cerebral ventricles were reliably segmented with minimal interaction. 
Hahn and Peitgen [2003] demonstrated the application to the challenging problem of
delineating individual bones in the human wrist (see Fig. 4.17). 
Kuhnigk et al. [2003] employed the above-described variant of the watershed segmentation 
to the delineation of lung lobes in CT data. 
Ray et al. [2008] used the iterative watershed transform 
for hepatic tumor segmentation (and volumetry).*/


</script>

</body>
</html>